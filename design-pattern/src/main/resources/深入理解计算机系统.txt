Dennis Richie 丹尼斯·里奇
Brian Kernighan 布莱恩·克尼根
Linus Torvalds 林纳斯·托瓦兹

了解编译系统如何工作：
1. 优化程序性能：
    一个 switch 语句是否总是比一些列的 if-else 语句高效的多？
    一个函数调用的开销有多大?
    while 循环比 for 循环更有效吗？
    指针引用比数组索引更有效吗？
    为什么将循环求和的结果放到一个本地变量中，会比将其放到一个通过引用传递过来的参数中，运行起来快很多呢？
    为什么我们只是简单地重新排列以下算数表达式中的括号就能让函数运行得更快？
2. 理解链接时出现的错误：
    链接器报告说它无法解析一个引用，这是什么意思？
    静态变量和全局变量的区别是什么？
    如果你在不同的 C 文件中定义了名字相同的两个全局变量会发生什么？
    静态库和动态库的区别是什么？
    我们在命令行上排列库的顺序有什么影响？
    为什么有些链接错误直到运行时才会出现？
3. 避免安全漏洞：
    限制从不受信任的源接收数据的数量和格式。
    理解数据和控制信息存储在程序栈上的方式会引起的后果。
    堆栈原理和缓冲区溢出错误。

系统的硬件组成:
1. 总线.
   贯穿整个系统的是一组电子管道, 称总线.
   它携带信息字节并负责在各个部件间传递. 通常总线被设计成传送定长的字节块, 也就是 字(word).
   字中的字节数(即字长)是一个基本的系统参数, 各个系统中都不尽相同. 现在的大多数机器字长要么是 4 个字节(32位),
   要么是 8 个字节(64位).
2. I/O 设备.
    I/O 设备是系统与外部世界的联系通道. 我们的示例系统包括四个 I/O 设备: 作为用户输入的键盘和鼠标, 作为用户输出的显示器,
    以及用于长期存储数据和程序的磁盘驱动器(磁盘).
    每个 I/O 设备都通过一个控制器或适配器与 I/O 总线相连. 控制器和适配器之间的区别在于它们的封装方式.
    控制器 是 I/O 设备本身或者系统的主印制电路板(主板)上的芯片组.
    适配器 是一块插在主板插槽上的卡.
    它们的功能都是在 I/O 总线和 I/O 设备之间传递信息.
3. 主存.
    主存是一个临时存储设备, 在处理器执行程序时, 用来存放程序和程序处理的数据.
    从物理上来说, 主存是一组 动态随机存取存储器(DRAM: dynamic random access memory)芯片组成的.
    从逻辑上来说, 存储器是一个线性的字节数组, 每个字节都有其唯一的地址(数组索引), 这些地址是从零开始的.
4. 处理器.
    中央处理单元 CPU(central processing unit), 简称处理器, 是解释(或执行)存储在主存中指令的引擎.
    处理器的核心是一个大小为一个字的存储设备(或寄存器), 称为 程序计数器(PC: program counter).
    在任何时刻, PC 都指向主存中的某条机器语言指令(即含有该条指令的地址).
    从系统通电开始, 直到系统断电, 处理器一直在不断地执行 程序计数器 指向 地指令, 再更新程序计数器, 使其指向下一条指令.
    处理器 看上去是按照一个非常简单地指令执行模型来操作的, 这个模型是由指令集架构决定的.
    在这个模型中, 指令按照严格的顺序执行, 而执行一条指令包含执行一系列的步骤. 处理器从程序计数器指向的内存处读取指令,
    解释指令中的位, 执行该指令指示的简单操作, 然后更行 PC, 使其指向下一条指令, 而这条指令并不一定和在内存中刚刚执行的指令相邻.
    这样的简单操作并不多, 它们围绕着主存、寄存器文件(register file)和 算术/逻辑单元(ALU: arithmetic and logic unit) 进行.
    寄存器文件 是一个小的存储设备, 由一些单个字长的寄存器组成, 每个寄存器都有唯一的名字. ALU 计算新的数据和地址值.
    下面是一些简单操作的例子, CPU 在指令的要求下可能会执行这些操作.
     -- 加载: 从主存复制一个字节或者一个字到寄存器, 以覆盖寄存器原来的内容.
     -- 存储: 从寄存器复制一个字节或者一个字到主存的某个位置, 以覆盖这个位置上原来的内容.
     -- 操作: 把两个寄存器的内容复制到 ALU, ALU 对这两个做算术运算, 并将结果存放到一个寄存器中, 以覆盖该寄存器中原来的内容.
     -- 跳转: 从指令本身中抽取一个字, 并将这个字复制到程序计数器(PC)中, 以覆盖 PC 中原来的值.
     处理器 看上去是它的指令集架构的简单实现, 但是实际上现代处理器使用了非常复杂的机制来加速程序的执行. 因此, 我们将处理器的指令集
     架构和处理器的微体系结构区分开来: 指令集架构 描述的是每条机器代码指令的效果; 而 微体系结构 描述的是处理器实际上是如何实现的.

高速缓存: 静态随机访问存储器(SRAM: static random access memory)技术.


抽象: 计算机系统中的一个重大主题就是提供不同层次的抽象表示, 来隐藏实际实现的复杂性.
    1. 文件 是对 I/O 设备的抽象.
    2. 虚拟内存 是对 程序存储器(主存 和 磁盘) 的抽象. 虚拟内存 为每个进程提供了一个假象, 即每个进程都在独占地使用主存.
        每个进程看到的内存都是一致的, 称为 虚拟地址空间.
    3. 指令集架构 是对 处理器硬件的抽象. 使用这个抽象, 机器代码程序表现得就好像运行在一个一次只执行一条指令的处理器上.
        低层的硬件远比抽象描述的要复杂精细, 它并行地执行多条指令, 但又总是与那个简单有序的模型保持一致. 只要执行模型一样, 不同的
        处理器实现也能执行同样的机器代码, 而又提供不同的开销和性能.
    3. 进程 是对一个正在运行的程序的抽象 -- 包括 (处理器+主存+I/O设备). 在一个系统上可以同时运行多个进程, 而每个进程都好像在独占地使用硬件.
         并发运行: 一个进程的指令和另一个进程的指令是交错执行的.
         操作系统实现这种交错执行的机制称为 上下文切换.
         操作系统保持跟踪进程所需的所有状态信息, 这种状态就是 上下文, 包括许多信息, 比如 PC 和寄存器文件的当前值, 以及主存的内容.
            在任何时刻,单处理器系统都只能执行一个进程的代码. 当操作系统决定要把控制权从当前进程转移到某个新进程时,就会进行 上下文切换,
            即 保存当前进程的上下文、恢复新进程的上下文,然后将控制权传递到新进程. 新进程就会从它上次停止的地方开始.
       线程: 一个进程可以由多个称为 线程 的执行单元组成, 每个线程都运行在进程的上下文中, 并共享同样的代码和全局数据.
    4. 虚拟机 是对整个计算机的抽象, 包括操作系统、处理器和程序. 保证一个计算机可以运行不同的操作系统或同一操作系统的不同版本设计的程序.

文件.
-- 文件就是字节序列, 仅此而已. 每个 I/O 设备, 包括 磁盘、键盘、显示器, 甚至网络, 都可以看成是 文件.
   系统中的所有输入输出都是通过使用一个小组成为 Unix I/O 的系统函数调用读写文件来实现的.
   文件 这个简单而精致的概念是非常强大的, 因为它向应用程序提供了一个统一的视图, 来看待系统中可能含有的所有各式各样的 I/O 设备.

抽象 的使用是计算机科学中最为重要的概念之一. 例如, 为一组函数规定一个简单的应用程序接口(API: application programming interface)
    是一个很好的编程习惯, 程序员无需了解它内部的工作便可以使用这些代码. 不同的的编程语言提供不同形式和等级的抽象支持, 例如 Java 类的声明
    和 C 语言的函数原型.

:-)

Amdahl 定律. Gene Amdahl. Amdahl's law. 阿姆达尔定律.
-- 该定律的主要思想是, 当我们对系统的某个部分加速时, 其对系统整体性能的影响取决于该部分的重要性和加速程度.
   若系统执行某应用程序需要时间位 T(old). 假设系统某部分所需执行时间与该时间的比例位 α, 而该部分性能提升比例位 k.
   即该部分初始所需时间位 αT(old), 现在所需时间为 (αT(old))/k. 因此, 总的执行时间应为:
    T(new) = (1 - α)T(old) + (αT(old))/k = T(old)[(1 - α) + α/k]
    -- 由此, 可以计算加速度比 S = T(old)/T(new) 为
       S = 1/((1 - α) + α/k)
  eg: 系统的某个部分初始耗时比例为 60%(α = 0.6), 其加速比例因子为 3(k = 3). 则我们可以获得的加速比为 1/[0.4 + 0.6/3] = 1.67 倍.
    虽然我们对系统的一个主要部分做出了重大改进, 但是获得的系统加速比却明显小于这部分的加速比.
    这就是 Amdahl 定律的主要观点 -- 想要显著加速整个系统, 必须提升全系统中相当大的部分的速度.

并行和并发
-- 数字计算机的整个历史中, 有两个需求是驱动进步的持续动力: 一个是我们想要计算机做得更多, 另一个是我们想要计算机运行得更快.
   当处理器能够同时做更多的事情时, 这两个因素都会改进.
   并发 concurrency: 指一个同时具有多个活动的系统;
   并行 parallelism: 指用并发来使一个系统运行得更快.
-- 按照系统层次结构中由高到低得顺序重点强调三个层次:
   1. 线程级并发
       构建在 进程 这个抽象之上, 我们能够设计出同时有多个程序执行的系统, 这就导致了 并发. 使用 线程, 我们甚至能够
       在一个 进程 中执行多个 控制流.
       传统意义上, 这种 并发执行 只是 模拟 出来的, 是通过使一台计算机在它正在执行的 进程 间快速切换来实现的, 就好像
       一个杂耍艺人保持多个球在空中飞舞一样. 这种 并发 形式允许多个用户同时与系统交互, 例如, 当许多人想要从一个 Web 服务器
       获取页面时. 它还允许一个用户同时从十多个任务, 例如, 在一个窗口中开启 Web 浏览器, 在另一个窗口中运行字处理器,
       同时又播放音乐. 在以前, 即使处理器必须在多个任务间切换, 大多数实际的计算也都是由一个处理器来完成的. 这种配置称为
       单处理器系统.
   当构建一个由 单操作系统内核 控制的 多处理器 组成的系统时, 我们得到了一个 多处理器系统.
   -- 多处理器系统 包括 多核, 超线程(hyper-threading).
       -- 多核处理器 将多个 CPU(称为"核") 集成到一个集成到电路芯片上. 每个核都有自己的 L1 和 L2 高速缓存, 其中 L1 告诉缓存分为
          两个部分 -- 一个保存最近去到的指令, 另一个存放数据. 这些核共享更高层次的告诉缓存, 以及到主存的接口.
       -- 超线程, 有时称为 同时多线程(simultaneous multi-threading), 是一项允许一个 CPU 执行多个控制流的技术.
          它涉及 CPU 某些硬件有多个备份, 比如 程序计数器 和 寄存器文件, 而其他的硬件部分只有一份, 比如执行浮点算术运算的单元.
          常规的处理器需要大约 20,000 个时钟周期做不同线程间的转换, 而超线程的处理器可以在单个周期的基础上决定要执行哪个线程.
          这使得 CPU 能够更好地利用它地处理资源. 比如, 假设一个线程必须等到某些数据被装载到高速缓存中, 那 CPU 就可以继续去执行另一个线程.
          eg: Intel Core i7 处理器可以让每个核执行两个线程, 所以一个 4 核的系统实际上可以并行地执行 8 个线程.
       多处理器 的使用可以从两方面提高系统性能.
       首先, 它减少了在执行多个任务时模拟并发的需要. 正如前述, 即使是只有一个用户使用的个人计算机也需要并发地执行多个活动.
       其次, 它可以使应用程序运行得更快, 当然, 这必须要求程序是以多线程方式来书写的, 这些线程可以并行地高效执行.
   2. 指令级并行
       在较低的抽象层次上, 现代处理器可以同时执行多条指令的属性称为 指令级并行.
       其实每条指令从开始到结束需要长得多的时间, 大约 20 个或者更多周期,但是处理器使用了非常多的聪明技巧来同时处理多达 100 条指令.
       此即 流水线(pipelining)的使用, 在流水线中, 将执行一条指令所需要的活动划分为不同的步骤, 将处理器的硬件组织成一系列的阶段, 每个阶段执行一个步骤.
       这些阶段可以 并行 地操作, 用来处理不同指令地不同部分.
       如果处理器可以达到比一个周期一条指令更快的执行效率, 就称为 超标量(super-scalar)处理器.
   3. 单指令、多数据并行
       在最低层次上, 许多现代处理器拥有特殊的硬件, 允许一条指令产生多个可以并行执行的操作, 这种方式称为 单指令、多数据,
       即 SIMD(Single Instruction Multiple Data 单指令多数据流) 并行.

---
计算机系统由硬件和系统软件组成, 它们共同协作以运行应用程序. 计算机内部的信息被表示为一组组的为, 它们依据上下文有不同的解释方式.
程序被其他程序翻译成不同的形式, 开始时是 ASCII 文本, 然后被 编译器 和 链接器 翻译成二进制可执行文件.
处理器 读取并解释存放在主存里得二进制指令. 因为计算机花费大量得时间在内存、I/O 设备和 CPU 寄存器之间复制数据, 所以将系统中的存储设备
划分成层次结构 -- CPU 寄存器在顶部, 接着是多层的硬件高速缓存存储器、DRAM 主存和磁盘存储器.
---
现代计算机存储和处理的信息以二值信号表示. 这些微不足道的二进制数字, 或者称为 位(bit), 形成了数字革命的基础.
孤立地讲, 单个的位不是非常有用. 然而, 当把位组合在一起, 再加上某种解释(interpretation), 即赋予不同的可能位模式以含意,
我们就能表示任何有限集合的元素.
数字的表示:
-- 无符号(unsigned)编码: 基于传统的二进制表示法, 表示大于或者等于零的数字(非负数).
-- 补码(two's-complement)编码: 表示有符号整数的最常见的方式, 有符号整数就是可以为正或者为负的数字.
-- 浮点数(floating-point)编码: 表示实数的科学计数法的以 2 为基数的版本.

整数的表示虽然只能编码一个相对较小的数值范围, 但是这种表示是精确的; 而浮点数虽然可以编码一个较大的数值范围, 但是这种表示只是近似的.
通过研究数字的实际表示, 我们能够了解可以表示的值的范围和不同算术运算的属性. 为了使编写的程序能在全部数值范围内正确工作, 而且具有
可以跨越不同机器、操作系统和编译器组合的可移植性, 了解这种属性是非常重要的. 大量计算机的安全漏洞都是由于计算机算术运算的微妙细节引发的.

信息存储：
    大多数计算机使用 8 位的块, 或者 字节(byte), 作为最小的可寻址的内存单位, 而不是访问内存中 单独的位.
    机器级程序将内存视为一个非常大的字节数组, 称为 虚拟内存(virtual memory).
    内存的每个字节都有一个唯一的数字来标识, 称为它的 地址(address), 所有可能地址的集合就称为 虚拟地址空间(virtual address space).
    顾名思义, 这个虚拟地址空间只是一个展现给机器级程序的概念性映像. 实际的实现是将 动态随机访问存储器(DRAM)、闪存、磁盘存储器、特殊硬件和操作系统软件
    结合起来, 为程序提供一个看上去统一的字节数组.

指针: C 语言的一个重要特性. 它提供了引用数据结构(包括数组)的元素的机制. 与变量类似, 指针也有两个方面: 值和类型.
    它的值表示对象的位置, 而它的类型表示那个位置上所存储对象的类型(比如 整数或者浮点数).
    &x: "取地址" 运算符 & 创建一个指向保存变量 x 的位置的指针.

十进制 --> 十六进制(0x..) --> 二进制
当值 x 是 2 的非负整数 n 次幂时, 也就是 x = 2^n, 我们可以很容易地将 x 写成十六进制形式, 只要记住 x 的二进制表示就是 1 后面跟 n 个 0.
十六进制数字 0 代表 4 个二进制 0. 所以, 当 n 表示成 i + 4j 的形式, 其中 0 <= i <= 3, 我们可以把 x 写成开头的十六进制数字为
    1(i = 0), 2(i = 1), 4(i = 2) 或者 8(i = 3), 后面跟随着 j 个十六进制的 0.
   比如, x = 2048 = 2^11, 我们有 n = 11 = 3 + 4 * 2, 从而得到十六进制表示 0x800.

字数据大小
    每台计算机都有一个字长(word size), 指明指针数据的标称大小(nominal size).
    因为虚拟地址是以这样一个字来编码的, 所以字长决定的最重要的系统参数就是虚拟地址空间的最大大小. 也就是说, 对于一个字长为 w 位的机器而言,
    虚拟地址的范围位 0 ~ 2^w - 1, 程序最多访问 2^w 个字节.
寻址和字节顺序
    对于跨越多字节的程序对象, 我们必须建立两个规则: 这个对象的地址是什么, 以及在内存中如何排列这些字节.
    在几乎所有的机器上, 多字节对象都被存储为连续的字节序列, 对象的地址为所使用字节中最小的地址. 例如, 假设一个类型为 int 的变量 x 的地址
    为 0x100, 也就是说, 地址表达式 &x 的值为 0x100. 那么, (假设数据类型 int 为 32 位表示) x 的 4 个字节将被存储在内存的 0x100, 0x101, 0x102 和 0x103 位置.
小端法 little endian: 在内存中按照从最低有效字节到最高有效字节的顺序存储对象(地址的低位 对应 数据的低位).
大端法 big endian: 在内存中按照从最该有效字节到最低有效字节的顺序存储(地址的高位 对应 数据的高位).
    eg: 假设变量 x 的类型为 int, 位于地址 0x100 处, 它的十六进制为 0x01234567. 地址范围 0x100 ~ 0x103 的字节顺序依赖于机器的类型.
        大端法:
            地址  0x100  0x101  0x102  0x103
            数据   01     23     45      67
        小端法:
            地址  0x100  0x101  0x102  0x103
            数据   67     45     23     01
     注意: 在字 0x01234567 中, 高位字节的十六进制值为 0x01, 而低位字节值为 0x67.

反汇编器: disassembler. 一种确定可执行程序文件所表示的指令序列的工具.

表示字符串
    C 语言中 字符串被编码为一个以 null(其值为 0)字符结尾的字符数组.
    'a' ~ 'z' 的 ASCII 码为 0x61 ~ 0x7A (97 ~ 112).


逻辑符号:
    ~: 非, NOT
    &: 与, AND
    |: 或, OR
    ^: 异或, exclusive-or. 当二者有真且不同时为真时, 结果为真.

逻辑右移与算术右移
   逻辑右移: 左端补 0.
   算术右移: 左端补最高有效位的值(符号位).
 eg:
    操作                             值
   参数 x                     [0110 0011] [1001 0101]
   x << 4                     [0011 0000] [0101 0000]
   x >> 4 (逻辑右移)          [0000 0110] [0000 1001]
   x >> 4 (算术右移)          [0000 0110] [1111 1001]
 注:
  1. C 语言标准没有明确定义对于 有符号数 应该使用哪种类型的右移 -- 算术右移或者逻辑右移都可以.
     另一方面, 对于无符号数, 右移必须是 逻辑的.
  2. Java 对于如何进行右移有明确的定义. 表达式是 x >> k 会将 x 算术右移 k 个位置,
     而 x >>> k 会对 x 做逻辑右移.

整数表示
    符号           类型              含义              全名
    B2T            函数          二进制转补码         binary to two's-complement
    B2U            函数          二进制转无符号数     binary to unsigned
    U2B            函数          无符号数转二进制     unsigned to binary
    U2T            函数          无符号转补码
    T2B            函数          补码转二进制
    T2U            函数          补码转无符号数
    TMin           常数          最小补码值
    TMax           常数          最大补码值
    UMax           常数          最大无符号数
      注: B -- binary                二进制
          T -- two's complement      补码
          U -- unsigned              无符号

C, C++ 都支持有符号(默认)和无符号数. Java 只支持有符号数.

补码编码(B2T: binary to two's-complement)
    补码 two's-complement: 最常见的 有符号数 的计算机表示方式.
    在这个定义中, 将字的最高有效位解释为 负权(negative weight).
    最高有效位 也称为 符号位, 它的 "权重" 为 无符号表示中权重的负数.
    符号位被设置为 1 时, 表示值为 负, 而当设置为 0 时, 值为非负.

C 语言标准并没有要求要用补码形式来表示有符号整数, 但是几乎所有的机器都是这么做的.

反码: Ones' Complement
    直接取反. -- 补码是取反加一(最高位的权重的负数形式).
原码: Sign-Magnitude
    最高有效位是符号位, 用来确定剩下的位应该取 负权还是正权.
 这两种表示方法都有一个奇怪的属性, 那就是对于数字 0 有两种不同的编码方式.
 这两种表示方法, 把 [00...0] 都解释为 +0. 而值 -0 在 原码 中表示为 [00...0],
 在 反码 中表示为 [11...1]. 虽然过去生产过基于 反码表示的机器, 但是几乎所有的现代机器都使用补码.
 我们将看到在浮点数中有使用 原码编码.
 注: 补码(Two's complement) 和 反码(Ones' complement) 中撇号的位置是不同的.
    术语 补码 来源于这样一个情况, 对于 非负数 x, 我们用 2^w - x (这里只有一个 2)来计算 -x 的 w 位表示.
    术语 反码 来源于这样一个属性, 我们用 [111...1] - x (这里有很多个 1)来计算 -x 的反码表示.

C 语言中的有符号数和无符号数
    C 语言支持所有整型数据类型的有符号和无符号运算. 尽管 C 语言标准没有指定有符号数要采用某种表示, 但是
    几乎所有的机器都是用补码. 通常, 大多数数字都默认为是 有符号的. 例如, 当声明一个像 12345 或者 0x1A2B 这样的常量时,
    这个值就被认为是 有符号的. 要创建一个 无符号常量, 必须加上后缀字符 "U" 或者 "u", 例如, 12345U 或者 0x1A2Bu.
    C 语言允许无符号数和有符号数之间的转换. 虽然 C 标准没有精确规定应该如何进行这种转换, 但大多数系统遵循的原则是
    低层的位标识保持不变. 因此, 在一台采用 补码的机器上, 当从无符号数转换为有符号数时, 效果就是应用函数 U2T, 而从有符号数
    转换为 无符号数时, 就是应用函数 T2U.
    当用 printf 输出数值时, 分别用指示符 %d, %u, %x 以有符号十进制, 无符号十进制和十六进制格式输出一个数字.
    由于 C 语言对同时包含有符号和无符号数表达式的这种处理方式, 出现了一些奇特的行为. 当执行一个运算时, 如果它的一个运算数
    是 有符号的, 而另一个是 无符号的, 那么 C 语言会隐式地将 有符号参数 强制类型转换为 无符号数, 并假设这两个数都是 非负的,
    来执行这个运算. 这种方法对于标准的算术运算来说并无多大差异, 但是对于像 < 和 > 这样的关系运算符来说, 它会导致非直观的结果.

扩展一个数字的位表示
    一个常见的运算是在不同字长的整数之间转换, 同时又保持数值不变. 当然, 当目标数据类型太小以至于不能表示想要的值时, 这根本就是不可能的.
    然而, 从一个较小的数据类型转换到一个较小的类型, 应该总是可能的.
    要将一个 无符号数 转换为一个更大的数据类型, 我们只要简单地在表示的开头添加 0. 这种运算称为 零扩展(zero extension).
    要将一个 补码数字 转换为一个更大的数据类型, 可以执行一个 符号扩展(sign extension), 在表示中添加最高有效位的值.

GCC C 语言编译器以汇编代码的形式产生输出, 汇编代码是机器代码的文本表示, 给出程序中的每一条指令.
然后 GCC 调用 汇编器 和 链接器, 根据 汇编代码 生成可执行的 机器代码.

为甚要花时间学习机器代码?
 即使 编译器 承担了生成汇编代码的大部分工作, 对于严谨的程序员来说, 能够阅读和理解 汇编代码 仍是一项重要的技能.
 以适当的命令行选项调用编译器, 编译器就会产生一个以汇编代码形式表示的输出文件. 通过阅读 汇编代码, 我们能够理解
 编译器 的优化能力, 并分析代码中隐含的低效率.
 视图最大化一段关键代码性能的程序员, 通常会尝试源代码的各种形式, 每次编译并检查产生的汇编代码, 从而了解程序将要
 运行的效率如何. 此外, 也有些时候, 高级语言提供的抽象层会隐藏我们想要了解的程序的运行时行为.
 例如, 用线程包写并发程序时, 了解不同的程序是如何共享程序数据或保持数据私有的, 以及准确知道如何在哪里访问共享数据,
 都是很重要的.
 这些信息在机器代码级是可见的.
 程序遭到攻击(使得恶意软件侵扰系统)的许多方式中, 都涉及程序存储运行时控制信息的方式的细节. 许多攻击利用了系统程序中
 的漏洞重写信息, 从而获得了系统的控制权. 了解这些漏洞是如何出现的, 以及如何防御他们, 需要具备程序机器级表示的知识.
 程序员学习汇编代码的需求随着时间的推移也发生了变化, 开始时要求程序员能直接用汇编语言编写程序, 现在则要求他们能够阅读
 和理解编译器产生的代码.

机器级代码
   对于机器级编程来说, 其中两种抽象尤为重要.
   第一种是由 指令集体系结构(指令集架构)(Instruction Set Architecture, ISA) 来定义机器级程序的格式和行为, 它定义了
       处理器状态、指令的格式, 以及每条指令对状态的影响.
   第二种抽象是, 机器级程序 使用的内存地址是虚拟地址, 提供的内存模型看上去是一个非常大的字节数组.
       存储器系统的实际实现是将多个硬件存储器和操作系统软件组合起来.
   在整个编译过程中, 编译器会完成大部分的工作, 将把用 C 语言提供的相对比较简单的执行模型表示的程序转化成处理器执行的
   非常基本的指令. 汇编代码表示非常接近于机器代码. 与机器代码的二进制格式相比, 汇编代码的主要特点是它用 可读性更好的
   文本格式表示. 能够理解汇编代码以及它与原始 C 代码的联系, 是理解计算机如何执行程序的关键一步.

关于指针:
    long x = *xp; -- 读.
    将都存储在 xp 所指位置中的值, 并将它存放到名字为 x 的局部变量中. 这个读操作称为 指针的间接引用(pointer dereferencing)
    C 操作符 * 执行指针的间接引用.
    *xp = y; -- 写.
    将参数 y 的值写到 xp 所指的位置. 这也是指针间接引用的一种形式(所以又操作符 *), 但是它表明的是一个 写操作, 因为它在赋值语句的左边.
    -------------------------------------------------
    long a = 4;
    long = exchange(&a, 3);
    printf("a = %ld, b = %ld\n", a, b);

    long exchange(long *xp, long y) {
        long x = *xp;
        *xp = y;
        return x;
    }
    ---------------------------------------------------
    C 操作符 & (称为"取址"操作符)创建一个指针, 在本例中, 该指针指向保存局部变量 a 的位置.
    然后, 函数 exchange 将用 3 覆盖存储在 a 中的值, 但是返回原来的值 4 作为函数的值. 注意如何
    将指针传递给 exchange, 它能修改存在某个远处位置的数据.

栈操作说明. 根据惯例, 我们的栈是倒过来画的, 因而栈 "顶" 在底部. x86-64 中, 栈向低地址方向增长, 所以压栈是
减小栈指针(寄存器 %rsp)的值, 并将数据存放到内存中, 而出栈是从内存中读数据, 并增加栈指针的值.

指针运算
   C 语言允许对指针进行运算, 而计算出来的值会根据该指针引用的数据类型的大小进行伸缩。 也就是说,
   如果 p 是一个指向类型为 T 的数据的指针, p 的值为 x(下标p), 那么表达式 p + i 的值为 x(下标p) + L·i,
   这里 L 是数据类型 T 的大小.
   单操作数操作符 & 和 * 可以产生指针和间接引用指针. 也就是, 对于一个表示某个对象的表达式 Expr, &Expr 是
   给出该对象地址的一个指针. 对于一个表示地址的表达式 AExpr, *AExpr 给出该地址处的值. 因此, 表达式 Expr 与
   *&Expr 是等价的. 可以对数组和指针应用数组下标操作. 数组引用 A[i] 等同于表达式 *(A + i). 他计算第 i 个数组元素的\
   地址, 然后访问这个内存位置.

异质的数据结构
    C 语言提供了两种将不同类型的对象组合到一起创建数据类型的机制: 结构(structure), 用关键字 struct 来声明,
    将多个对象集合到一个单位中; 联合(union), 用关键字 union 来声明, 允许用几种不同的类型来引用一个对象.
  结构
    C 语言的 struct 声明创建一个数据类型, 将可能不同类型的对象聚合到一个对象中. 用名字来引用结构的各个组成部分.
    类似于数组的实现, 结构的所有组成部分都存放在内存中一段连续的区域内, 而指向结构的指针就是结构第一个字节的地址.
    编译器维护关于每个类型的信息, 指示每个字段(field)的字节偏移. 它以这些偏移作为内存引用指令中的位移, 从而产生对结构元素的引用.

    C 语言提供的 struct 数据类型的构造函数(constructor)与 C++ 和 Java 的对象最为接近. 它允许程序员在一个数据结构中保存
    关于某个实体的信息, 并用名字来引用这些信息.

  联合
    联合提供了一种方式, 能够规避 C 语言的类型系统, 允许以多种类型来引用一个对象. 联合声明的语法与结构的语法一样, 只不过语义相差
    比较大.

理解指针
   1. 每个指针都对应一个类型. 这个类型表明该指针指向的是哪一类对象.
       int *ip;
       char **cpp;
       变量 ip 是一个指向 int 类型对象的指针, 而 cpp 指针指向的对象自身就是一个指向 char 类型对象的指针. 通常, 如果对象类型为 T,
       那么指针的类型为 T *. 特殊的 void * 类型代表通用指针. 比如说, malloc 函数返回一个通用指针, 然后通过显示强制类型转换或者
       赋值操作那样的隐式强制类型转换, 将它转换成一个有类型的指针. 指针类型不是机器代码中的一部分; 它们是 C 语言提供的一种抽象,
       帮助程序员避免寻址错误.
   2. 每个指针都有一个值.
       这个值是某个指定类型的对象的地址. 特殊的 NULL(0) 值表示指针没有指向任何地方.
   3. 指针用 "&" 运算符创建.
       这个运算符可以应用到任何 lvalue 类的 C 表达式上, lvalue 意指可以出现赋值语句左边的表达式. 这样的例子包括变量以及结构、
       联合和数组的元素。
   4. * 操作符用于间接引用指针.
       其结果是一个值, 它的类型与该指针的类型一致. 间接引用是用内存引用来实现的, 要么是存储到一个指定的地址, 要么是从指定的地址读取.
   5. 数组与指针紧密联系.
       一个数组的名字可以像一个指针变量一样引用(但是不能修改). 数组引用(a[3])与指针运算和间接引用(*(a + 3))有一样的效果.
       数组引用和指针运算都需要用对象大小对偏移量进行伸缩. 当我们写表达式 p + i, 这里指针 p 的值为 p, 得到的地址计算为 p + L·i,
       这里 L 是与 p 相关联的数据类型的大小.
   6. 将指针从一种类型强制转换成另一种类型, 只改变它的类型, 而不改变它的值.
       强制类型转换的一个效果是改变指针运算的伸缩. 例如, 如果 p 是 char * 类型的指针, 它的值为 p, 那么表达式 (int * )p + 7 计算为
       p + 28, 而 (int *)(p + 9) 计算为 p + 7. (强制类型转换的优先级高于加法)
   7. 指针也可以指向函数.
       这提供了一个很强大的存储和像代码传递引用的功能, 这些引用可以被程序的某个其他部分调用.
       例如, 如果我们有一个函数, 用下面这个原型定义:
       int fun(int x, int *p);
       然后, 我们可以声明一个指针 fp, 将它赋值为这个函数, 代码如下:
       int (*fp)(int, int *);
       fp = fun;
       然后用这个指针来调用这个函数:
       int y = 1;
       int result = fp(3, &y);
       函数指针的值是该函数机器代码表示中第一条指令的地址.

Just-in-time compilation 即(及?)时编译: java, 动态地将字节代码序列翻译成机器指令.
    当代码要执行多次时(例如在循环中), 这种方法执行起来更快. 用字节代码作为程序的低级表示,
    优点是相同的代码可以在许多不同的机器上执行.

---------------------------------------------------------------
处理器体系结构 -- 硬件设计.
ISA: Instruction-Set Architecture 指令集体系结构.
    一个处理器支持的指令和指令的字节级编码.
    ISA 在编译器编写者和处理器设计人员之间提供了一个概念抽象层, 编译器编写者只需要知道允许哪些指令, 以及它们是如何编码的;
    而处理器设计者必须建造出执行这些指令的处理器.
现代处理器的实际工作方式可能跟 ISA 隐含的计算模型大相径庭. ISA 模型看上去应该是 顺序指令执行, 也就是先取出一条指令, 等到它执行完毕,
    再开始下一条. 然而, 与一个时刻只执行一条指令相比, 通过同时处理多条指令的不同部分, 处理器可以获得更高的性能. 为了保证处理器能得到同顺序
    执行相同的结果, 人们采用了一些特殊的机制. 在计算机科学中, 用巧妙的方法在提高性能的同时又保持一个更简单、更抽象模型的功能, 这种思想是众所周知的.
你可能永远都不会自己设计处理器. 这是专家们的任务, 他们工作在全球不到 100 家的公司里. 那么为什么你还应该了解处理器设计呢?
   1. 从智力方面来说, 处理器设计是非常有趣而且很重要的.
      学习事物是怎样工作的有其内在价值. 了解作为计算机科学家和工程师日常生活一部分的一个系统的内部工作原理(特别是对很多人来说这还是个谜), 是件
      格外有趣的事情. 处理器设计包括许多好的工程实践原理. 它需要完成复杂的任务, 而结构又要尽可能简单和规则.
   2. 理解处理器如何工作能帮助理解整个计算机系统如何工作的.
   3. 虽然很少有人设计处理器, 但是许多人设计包含处理器的硬件系统.
   4. 你的工作可能就是处理器设计.

HCL: Hardware Control Language 硬件控制语言.

编写高效程序需要做到以下几点:
    1. 必须选择一组适当的算法和数据结构;
    2. 必须编写出编译器能够有效优化以转换成高效代码的源代码.
  C 语言的有些特性, 例如执行指针运算和强制类型转换的能力, 使得编译器很难对它进行优化.
 程序优化的第一步就是消除不必要的工作, 让代码尽可能有效地执行所期望的任务. 这包括消除不必要的函数调用、条件测试
    和内存引用. 这些优化不依赖于目标机器的任何具体属性.
 研究程序的汇编代码表示 是理解编译器以及产生的代码会如何运行的最有效手段之一.

表示程序性能:
    CPE: Cycles Per Element, 度量标准每元素的周期, 作为一种表示程序性能并知道我们改进代码的方法.
    CPE 这种度量标准帮助我们在更细节的级别上理解迭代程序的循环性能.


存储器系统: memory system
    高速缓存存储器 -- cache memory
    主存储器 -- main memory
    RAM: random-access memory 随机访问存储器.
        -- 静态: SRAM  static
        -- 动态: DRAM  dynamic
        静态比动态更快, 更贵.
        SRAM 用来作为高速缓存存储器, 既可以在 CPU 芯片上, 也可以在片下.
        DRAM 用来作为主存以及图形系统的帧缓冲区.
        一般的, 一个桌面系统的 SRAM 不会超过几兆字节, 但是 DRAM 却有几百或几千兆字节.
        -- SRAM 将每个位存储在一个 双稳态的(bistable) 存储器单元里. 每个单元是用一个六晶体管电路来实现的.
        这个电路有这样一个属性, 它可以无限期地保持在两个不同的电压配置(configuration)或状态(state)之一.
        其他任何状态都是不稳定的 -- 从不稳定状态开始, 电路会迅速地转移到两个稳定状态中的一个.
        由于 SRAM 存储器单元的双稳态特性, 只要有电, 它就会永远地保持它的值. 即时有干扰来扰乱电压, 当干扰消除时, 电路就会恢复到稳定值.
        -- DRAM 将每个位存储为对一个电容的充电. 这个电容非常小, 通常只有大约 30 毫微微法拉.
    ROM: read-only memory
        如果断电, DRAM 和 SRAM 会丢失它们的信息, 从这个意义上说, 它们是易失的(volatile). 另一方面, 非易失性存储器(nonvolatile memory)
        即时是在关电后, 仍然保持着它们的信息. 现在很多种非易失性存储器. 由于历史原因, 虽然 ROM 中有的类型既可以读也可以写, 但是它们整体上都被称为
        只读存储器(ROM). ROM 是以它们能够被重编程(写)的次数和对它们进行重编程所用的机制来区分的.
        PROM(Programmable ROM, 可编程 ROM) 只能被编程一次. PROM 的每个存储器单元有一种 熔丝(fuse), 只能用高电流熔断一次.
        EPROM(Erasable Programmable ROM, 可擦写可编程 ROM) 有一个透明的石英窗口, 允许光到达存储单元. 紫外线








